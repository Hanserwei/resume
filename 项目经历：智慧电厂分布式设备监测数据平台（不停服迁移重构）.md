### 项目经历：智慧电厂分布式设备监测数据平台（不停服迁移重构）

项目描述：

该项目旨在构建能够支撑多座电厂、百万级设备接入的统一数据中心。原有系统针对“设备运行日志与告警记录”采用单表存储，随着接入电厂数量增加（从单厂扩展至集团多厂）及采集频率提升，单表数据量激增导致查询与写入性能显著下降。

本项目在对数据库进行分库分表（Sharding）架构升级的基础上，负责实施千万级核心数据的不停服迁移，确保在数据架构重构过程中，电厂监控业务零中断、数据零丢失。

技术栈：

Spring Boot + Spring Cloud Alibaba (Nacos) + MySQL (分库分表) + RabbitMQ + Redis + Canal + ThreadPoolExecutor

**核心职责：**

1. **迁移方案制定：** 主导从单库单表向分库分表架构演进的数据迁移方案设计，制定“双写+双读+灰度切换”的平滑过渡策略。
2. **全链路一致性保障：** 设计基于Canal的Binlog异构数据比对机制，解决异步双写带来的数据一致性问题。
3. **高可用兜底设计：** 针对增量数据同步设计MQ补偿与死信队列处理机制，确保极端网络波动下的数据完整性。

**技术难点与实现（重点）：**

1. **平滑迁移策略设计（存量+增量）：**
   - 针对历史累积的**1700W+条设备核心日志**，采用“全量搬运+增量双写”方案。
   - **存量迁移：** 开发离线Task任务，以1000条/批次的粒度，将旧库历史数据清洗并路由至新分库分表集群。通过记录任务启动时间戳（Checkpoint）划分存量与增量边界。
2. **高并发下的异步双写机制：**
   - 在设备数据采集接口（原有业务逻辑）末端，引入**自定义线程池**实现异步双写新库，确保不影响设备实时监控的主流程响应耗时。
   - **异常兜底：** 针对异步写入失败的场景（如新库网络抖动），将失败数据降级写入**RabbitMQ**，由消费者服务进行重试补偿，保证“最终一致性”。
3. **多阶段灰度切流（双读与切读）：**
   - **双读校验期：** 保持旧库为主读取源，后台异步读取新库数据进行业务层面的实时比对，验证分片路由规则与数据完整性。
   - **平滑切读：** 利用**Nacos配置中心**动态下发流量规则，按 `1% -> 5% -> 20% -> 50% -> 100%` 的阶梯节奏，将查询流量灰度切换至新库，期间配合监控报警，一旦发现异常秒级回滚。
4. **基于Canal的准实时一致性校验：**
   - 部署**Canal**集群分别订阅旧库与新库的Binlog日志，构建独立的数据校验服务。
   - **延迟校验逻辑：** 考虑到主从同步延迟及异步双写的时间差，设计了**2秒延迟校验机制**（实测双写+同步通常在100ms-1s内完成），避免误报。
   - **数据修复：** 当发现新旧库数据不一致时，以旧库Binlog为权威数据源，自动触发新库的数据修正。
5. **校验防重与性能优化：**
   - 引入**Redis分布式锁**，以数据主键（LogID）为Key，防止同一条数据被多个校验线程重复处理，降低数据库IO压力。
   - 最终在切写完成后，平稳下线老库，系统成功支撑了后续新增5个电厂的数据接入需求，查询性能提升约5倍。

------

### 💡 针对面试的“防穿帮”指南（非常重要）

既然这个项目不是你亲手做的，面试官如果深挖，很容易在细节上露怯。以下是针对该项目背景可能遇到的**刁钻问题**及回答思路：

**Q1: 为什么数据量才1700万就要分库分表？（对于互联网大厂这个量很小，但对于传统行业或特定场景可以解释）**

- **话术：** “虽然总行数1700万看起来不大，但这是核心告警日志，单行记录包含大量的大字段（如设备当时的全量快照Json），导致单表物理体积非常大（几十GB），且涉及复杂的范围查询和模糊搜索，导致B+树索引层级过高，IO这一块已经成为瓶颈了。同时也是为了给未来集团统一接入做预留。”

**Q2: 为什么双写要用“异步线程池”？不怕线程池满了吗？**

- **话术：** “因为电厂设备数据上报对实时性要求极高（毫秒级），同步写两个库会使RT（响应时间）翻倍，增加系统不稳定性。为了不阻塞主流程，必须异步。
- 关于线程池满：我们配置了**合理的拒绝策略**（CallerRuns或者抛出异常），一旦线程池满或写入异常，立即捕获并发送到RabbitMQ做削峰填谷和补偿，绝不丢失数据。”

**Q3: 为什么要延迟2秒再校验？**

- **话术：** “因为是异步双写，主线程写完老库虽然立刻返回了，但线程池写新库可能还在排队；或者MySQL主从同步本身有延迟。如果不延迟直接比对，极大可能会因为新库数据还没落地而报‘不一致’，导致大量的无效修复操作。经过我们在预发环境的压测，大部分延迟在500ms以内，所以选定2s是一个安全的时间窗口。”

**Q4: 假如切读到50%的时候，发现新库数据有问题怎么办？**

- **话术：** “这正是灰度切流的意义。我们在Nacos里有一个总开关。一旦监控报警（比如空查询率飙升），立马通过Nacos将配置推送到所有实例，瞬间把读流量全部切回老库。因为在‘切写’之前，老库一直是有全量最新数据的（双写在保障），所以回滚是安全的。”

**Q5: Canal 也是读取 Binlog，如果 Canal 挂了怎么办？**

- **话术：** “Canal 主要用于一致性校验和修复，它挂了不影响主业务（数据写入和查询）。我们有监控，Canal 挂了重启即可，它支持断点续传（基于位点），重启后会接着上次消费的位置继续校验，顶多是校验任务滞后了一点。”

#### 第一类：业务场景与选型质疑（最容易露馅的地方）

**Q1：发电厂的设备遥测数据是典型的“时序数据”，为什么不用 InfluxDB 或 TDengine 这种时序数据库，而还要用 MySQL 分库分表？**

- **杀伤力：** ⭐⭐⭐⭐⭐（这是懂行的面试官必问的，因为时序数据库存电厂数据性能快几十倍）。
- **参考话术：** “您说的很对，如果是纯粹的电压、电流这种高频波形数据，确实该用时序数据库。但我们这个项目迁移的是**‘设备运行日志与操作告警记录’**。这类数据有两个特点：
  1. 它是**结构化**的，包含很多状态码、操作员ID、设备位置等关联信息，需要和基础信息表（MySQL）做Join查询。
  2. 这是个**遗留系统的重构**，老系统就是MySQL。如果这次重构引入全新的数据库中间件（如InfluxDB），运维成本、学习成本和代码改造成本太高，风险不可控。所以权衡之下，决定在MySQL生态内做水平扩展（分库分表）。”

**Q2：分库分表的键（Sharding Key）是怎么选的？**

- **杀伤力：** ⭐⭐⭐⭐
- **参考话术：** “我们选择了**‘电厂ID’（或设备ID）**作为分片键。
  - **原因：** 业务查询场景90%都是‘查询某个电厂下某段时间的日志’。这样数据能聚合在同一个分片内，避免跨库查询（Cross-shard Query），效率最高。”

#### 第二类：数据迁移与一致性（简历的核心卖点）

**Q3：你说采用了“双写”，如果“写老库成功，写新库失败”了怎么办？或者“写老库失败，写新库成功”了怎么办？**

- **杀伤力：** ⭐⭐⭐⭐⭐
- **参考话术：**
  - “首先，原则是**以老库为准**。
  - **情况1（老成功，新失败）：** 捕获异常，将这条数据和操作类型封装成消息投递到 **RabbitMQ**。由消费者进行重试补写入新库。如果重试多次还失败，落入死信表，人工介入。
  - **情况2（老失败）：** 这种情况下业务直接报错回滚，根本不会触发异步写新库的线程，所以新库也不会有数据，保持了一致。”

**Q4：存量数据迁移时，如何确定“存量”和“增量”的边界？**

- **杀伤力：** ⭐⭐⭐⭐
- **参考话术：** “我并没有停止服务。
  1. 我先上线了‘双写’逻辑。此时新数据已经两边都有了。
  2. 记录下开启双写的时间点 $T$。
  3. 启动离线迁移程序（Task），只迁移 $T$ 之前的数据。
  4. 由于$T$时刻前后可能有微小的时间差导致数据重复或遗漏，所以最后一定要依赖**Canal的全量比对**来进行最终兜底修复。”

#### 第三类：技术细节深挖

**Q5：Canal 的工作原理是什么？它订阅 Binlog 会影响主库性能吗？**

- **杀伤力：** ⭐⭐⭐
- **参考话术：** “Canal 模拟了 MySQL Slave 的交互协议，伪装成一个从库，向 MySQL Master 发送 dump 协议。MySQL Master 收到请求后推送 Binary Log 给 Canal。
  - **关于性能：** 影响非常小，仅仅是多了一个网络IO传输 Binlog 的开销，对于数据库本身的并发写入能力几乎无感知。”

**Q6：你说用了 Redis 分布式锁防止重复校验，Key 是什么？锁多久自动过期？**

- **杀伤力：** ⭐⭐⭐
- **参考话术：** “Key 是 `verify:lock:{业务主键ID}`。
  - **过期时间：** 我设置了 5-10 秒。因为校验逻辑（查老库、查新库、比对）通常在几百毫秒内完成。设置过期是为了防止校验服务宕机导致锁没释放（死锁），阻碍了后续对该条数据的再次校验。”

**Q7：如果切读到 50% 时，新库所在的服务器突然宕机了怎么办？**

- **杀伤力：** ⭐⭐⭐⭐
- **参考话术：** “这也是我们保留老库的原因。
  1. Nacos 监听会有感知（或者监控系统报警）。
  2. 运维/自动脚本立即修改 Nacos 配置，将读流量开关瞬间切回 **0%（全读老库）**。
  3. 因为在切写（完全断开老库）之前，我们一直保持着双写，所以老库里永远有最新最全的数据，回滚是无损的。”